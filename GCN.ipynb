{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "cwwb=pd.DataFrame()\n",
    "gljy=pd.DataFrame()\n",
    "for i in range(2011,2019):\n",
    "    tmp=pd.read_excel('./财务舞弊相关数据/fraud'+str(i)+'.xlsx',sheet_name=0)\n",
    "    tmp['year']=i\n",
    "    cwwb=pd.concat([tmp,cwwb],ignore_index=True)\n",
    "    gljy=pd.concat([pd.read_excel('./关联交易双方数据/RPT'+str(i)+'.xlsx'),gljy],ignore_index=True)\n",
    "cwwb['node']=[str(cwwb.loc[i,'year'])+'company'+str(cwwb.loc[i,'code']) for i in cwwb.index]\n",
    "gljy['inNode']=[gljy.loc[i,'publish_date'][0:4]+'company'+str(gljy.loc[i,'trading_code']) for i in gljy.index]\n",
    "gljy['outNode']=[gljy.loc[i,'publish_date'][0:4]+'company'+str(gljy.loc[i,'rela_stockid']) for i in gljy.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split1 :\n",
    "\n",
    "best val auc:0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "class GraphConvolution(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, use_bias=True):\n",
    "        \"\"\"图卷积：L*X*\\theta\n",
    "        Args:\n",
    "        ----------\n",
    "            input_dim: int\n",
    "                节点输入特征的维度\n",
    "            output_dim: int\n",
    "                输出特征维度\n",
    "            use_bias : bool, optional\n",
    "                是否使用偏置\n",
    "        \"\"\"\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.use_bias = use_bias\n",
    "        self.weight = nn.Parameter(torch.Tensor(input_dim, output_dim))\n",
    "        if self.use_bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(output_dim))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        init.kaiming_uniform_(self.weight)\n",
    "        if self.use_bias:\n",
    "            init.zeros_(self.bias)\n",
    "\n",
    "    def forward(self, adjacency, input_feature):\n",
    "        \"\"\"邻接矩阵是稀疏矩阵，因此在计算时使用稀疏矩阵乘法\n",
    "    \n",
    "        Args: \n",
    "        -------\n",
    "            adjacency: torch.sparse.FloatTensor\n",
    "                邻接矩阵\n",
    "            input_feature: torch.Tensor\n",
    "                输入特征\n",
    "        \"\"\"\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        support = torch.mm(input_feature, self.weight.to(device))\n",
    "        output = torch.sparse.mm(adjacency, support)\n",
    "        if self.use_bias:\n",
    "            output += self.bias.to(device)\n",
    "        return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' + str(self.in_features) + ' -> ' + str(self.out_features) + ')'\n",
    "\n",
    "# ## 模型定义\n",
    "class GcnNet(nn.Module):\n",
    "    \"\"\"\n",
    "    定义一个包含两层GraphConvolution的模型\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=343,drop_out=0.1,embed_dim=1024):\n",
    "        super(GcnNet, self).__init__()\n",
    "        self.gcn1 = GraphConvolution(input_dim, embed_dim)\n",
    "        self.gcn2 = GraphConvolution(embed_dim, embed_dim)\n",
    "        self.mlp=nn.Linear(embed_dim,embed_dim)\n",
    "        self.output=nn.Linear(embed_dim,2)\n",
    "        \n",
    "        self.layer_norm=nn.LayerNorm(normalized_shape= embed_dim)\n",
    "    def forward(self, adjacency, feature,drop_out=0.5):\n",
    "        self.dropout = nn.Dropout(p=drop_out)\n",
    "        h1 = F.relu(self.dropout(self.gcn1(adjacency, feature)))\n",
    "        h2 = F.relu(self.dropout(self.gcn2(adjacency, h1)))\n",
    "        h2=self.layer_norm(h2)\n",
    "        h3=torch.sigmoid(self.dropout(self.mlp(h2)))\n",
    "        logits=self.output(h3)\n",
    "        return logits\n",
    "    \n",
    "from sklearn.metrics import roc_auc_score\n",
    "class myGCN:\n",
    "    def __init__(self,print_flag=False,early_stopping=True,seed=55):\n",
    "        self.printFlag=print_flag\n",
    "        self.early_stopping=early_stopping\n",
    "        flag = torch.cuda.is_available()\n",
    "        print(flag)\n",
    "        ngpu= 1\n",
    "        # Decide which device we want to run on\n",
    "        self.device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "        print(self.device)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        pass\n",
    "    def fit(self,adj,features,labels,train_mask,val_mask,test_mask,learning_rate=0.01,epochs=2000,weight=[1.0,2.0],l2_ratio=0.001,\n",
    "                dropout=0.2,min_epoch=1000,max_train_auc=0.99,min_train_auc=0.90,tolerance=200,embed_dim=1024):\n",
    "        weight_decay = l2_ratio\n",
    "        sample_size=features.size()[0]\n",
    "        feature_size=features.size()[1]\n",
    "        # 模型定义：Model, Loss, Optimizer\n",
    "        device = self.device\n",
    "        self.model = GcnNet(input_dim=feature_size,embed_dim=embed_dim).to(device)\n",
    "        self.criterion = torch.nn.CrossEntropyLoss(weight=torch.tensor(weight,requires_grad=False).to(device))\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        self.dropout=dropout\n",
    "        self.tensor_x = features.to(device)\n",
    "        self.tensor_y = labels.to(device)\n",
    "        tensor_train_mask = torch.from_numpy(train_mask).to(device)\n",
    "        tensor_test_mask = torch.from_numpy(test_mask).to(device)\n",
    "        tensor_val_mask=torch.from_numpy(val_mask).to(device)\n",
    "        indices = torch.from_numpy(np.asarray([adj.row, adj.col]).astype('int64')).long()\n",
    "        values = torch.from_numpy(adj.data.astype(np.float32))\n",
    "        \n",
    "        self.tensor_adjacency = torch.sparse.FloatTensor(indices, values, (sample_size,sample_size)).to(device)\n",
    "        ###train\n",
    "        train_loss,train_auc,val_auc,test_auc,best_e,best_val_auc=self.train(tensor_train_mask,tensor_val_mask,tensor_test_mask,epochs,min_epoch,max_train_auc,min_train_auc,tolerance)\n",
    "        return train_loss,train_auc,val_auc,test_auc,best_e,best_val_auc\n",
    "    def train(self,tensor_train_mask,tensor_val_mask,tensor_test_mask,epochs,min_epoch=1000,max_train_auc=0.98,min_train_auc=0.95,tolerance=200):\n",
    "        loss_history = []\n",
    "        val_auc_history = []\n",
    "        train_auc_history=[]\n",
    "        test_auc_history=[]\n",
    "        self.model.train()\n",
    "        train_y = self.tensor_y[tensor_train_mask]\n",
    "        stop_increasing=0\n",
    "        max_auc=0\n",
    "        train_auc_min_id=0\n",
    "        for epoch in range(epochs):\n",
    "            logits = self.model(self.tensor_adjacency, self.tensor_x,drop_out=self.dropout)  # 前向传播\n",
    "            train_mask_logits = logits[tensor_train_mask]   # 只选择训练节点进行监督\n",
    "            loss = self.criterion(train_mask_logits, train_y)    # 计算损失值\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()     # 反向传播计算参数的梯度\n",
    "            self.optimizer.step()    # 使用优化方法进行梯度更新\n",
    "            train_acc, _, _ = self.test(tensor_train_mask,drop_out=self.dropout)     # 计算当前模型训练集上的准确率\n",
    "            val_acc, _, _ = self.test(tensor_val_mask,drop_out=0.0)     # 计算当前模型在验证集上的准确率\n",
    "            test_acc, _, _ = self.test(tensor_test_mask,drop_out=0.0) \n",
    "            # 记录训练过程中损失值和准确率的变化，用于画图\n",
    "            loss_history.append(loss.item())\n",
    "            val_auc_history.append(val_acc.item())\n",
    "            train_auc_history.append(train_acc.item())\n",
    "            test_auc_history.append(test_acc.item())\n",
    "            if train_acc>min_train_auc and train_auc_min_id==0:\n",
    "                train_auc_min_id=epoch\n",
    "                print('epoch {} meet the min train auc requirement'.format(epoch))\n",
    "            if train_acc>=max_train_auc:\n",
    "                print('train auc meets the setting line:{}'.format(max_train_auc))\n",
    "                break\n",
    "            if epoch>min_epoch and val_acc.item()<max_auc:\n",
    "                stop_increasing+=1\n",
    "            else:\n",
    "                max_auc=val_acc.item()\n",
    "                stop_increasing=0\n",
    "            if self.early_stopping:\n",
    "                if stop_increasing>=tolerance:\n",
    "                    if self.printFlag:\n",
    "                        print('验证集收敛:epoch {}'.format(epoch))\n",
    "                    break\n",
    "            if epoch%100==0 and self.printFlag:\n",
    "                print(\"Epoch {:03d}: Loss {:.4f}, TrainAuc {:.4}, ValAuc {:.4f}\".format(\n",
    "                    epoch, loss.item(), train_acc.item(), val_acc.item()))\n",
    "        if self.early_stopping==True:\n",
    "            best_e=np.argmax(val_auc_history[min_epoch:])+min_epoch+1\n",
    "            best_val_auc=max(val_auc_history[min_epoch:])\n",
    "        else:\n",
    "            best_e=np.argmax(val_auc_history[train_auc_min_id:])+train_auc_min_id+1\n",
    "            best_val_auc=max(val_auc_history[train_auc_min_id:])\n",
    "        return loss_history,train_auc_history, val_auc_history,test_auc_history,best_e,best_val_auc\n",
    "# 测试函数\n",
    "    def test(self,mask,drop_out=0.1):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(self.tensor_adjacency, self.tensor_x,drop_out=drop_out)\n",
    "            test_mask_logits = torch.softmax(logits[mask],dim=1)\n",
    "            predict_y = test_mask_logits[:,1]\n",
    "            auc = roc_auc_score(self.tensor_y[mask].cpu().numpy(),predict_y.cpu().numpy())\n",
    "        return auc, test_mask_logits.cpu().numpy(), self.tensor_y[mask].cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best result for GCN: val auc 0.7116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "node_embedding=np.load('./data_preprocessing/dglke_result/ComplEx_KG5_3/KG5_ComplEx_entity.npy')\n",
    "node_dict=pd.read_csv('./data_preprocessing/dglke_dataset/KG5/entities.tsv',header=None,sep='\\t',quoting=csv.QUOTE_NONE,index_col=1).to_dict()[0]\n",
    "data=pd.read_csv('./data_preprocessing/RT_SC_B_features_v2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9366/9366 [01:53<00:00, 82.54it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "embed_dim=node_embedding.shape[1]\n",
    "new_col=list(range(0,embed_dim))\n",
    "for i in tqdm(data.index):\n",
    "    node=str(data.loc[i,'year'])+'.comp.'+ str(data.loc[i,'Stkcd'])\n",
    "    data.loc[i,new_col]=node_embedding[node_dict[node],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_matrix=sp.csr_matrix(pd.read_csv('./data_preprocessing/RT_SC_adj.cav').values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading {} dataset...\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import math\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "\n",
    "def sample_mask(idx, l):\n",
    "    \"\"\"Create mask.\"\"\"\n",
    "    mask = np.zeros(l)\n",
    "    mask[idx] = 1\n",
    "    \n",
    "    return np.array(mask, dtype=bool)\n",
    "\n",
    "def normalize_adj(adjacency):\n",
    "  adjacency += 0.0001*sp.eye(adjacency.shape[0])\n",
    "  degree = np.array(adjacency.sum(1))\n",
    "  d_hat = sp.diags(np.power(degree, -0.5).flatten())\n",
    "  return (d_hat.dot(adjacency).dot(d_hat)+sp.eye(adjacency.shape[0])).tocoo()\n",
    "def normalize_features(features):\n",
    "  return features / features.sum(1)\n",
    "def load_data(X,y,adj_matrix,train_ratio=0.7,test_ratio=0.1):\n",
    "    \"\"\"Load citation network dataset (cora only for now)\"\"\"\n",
    "    print('Loading {} dataset...')\n",
    "    idx_features_labels = X.copy()\n",
    "\n",
    "    features = sp.csr_matrix(idx_features_labels, dtype=np.float32)\n",
    "    labels =y.copy()\n",
    "\n",
    "    # build graph\n",
    "    \n",
    "    adj = sp.coo_matrix(adj_matrix, dtype=np.float32)\n",
    "\n",
    "\n",
    "    #features = normalize_features(features)\n",
    "    adj = normalize_adj(adj)\n",
    "\n",
    "\n",
    "    features = torch.FloatTensor(features.todense())\n",
    "    labels = torch.LongTensor(labels)\n",
    "    print('finished')\n",
    "    return adj, features, labels\n",
    "\n",
    "data=pd.read_csv('./data_preprocessing/RT_SC_B_features_v2.csv')\n",
    "financial_featrues=data\n",
    "X=financial_featrues.drop(['year','Stkcd','IndustryCode','label','EquityNatureID'],axis=1)\n",
    "for column in list(X.columns[X.isna().sum() > 0]):\n",
    "    mean_val = X[column].mean()\n",
    "    X[column].fillna(mean_val, inplace=True)\n",
    "\n",
    "#adj_matrix=sp.load_npz('./data_preprocessing/RT_SC_B_v3.npz')\n",
    "X=X.values\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "X=minmax_scale(X)\n",
    "y=financial_featrues['label'].values\n",
    "adj, features, labels=load_data(X,y,adj_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30644/30644 [00:00<00:00, 57200.34it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "sm_csv=pd.read_csv('./data_preprocessing/comp_relations/sameManager.csv')\n",
    "sm=np.zeros([9366,9366])\n",
    "node=pd.read_csv('./data_preprocessing/comp_relations/node_list.csv',index_col='0').to_dict(orient='index')\n",
    "for i in tqdm(sm_csv.index):\n",
    "    a=node[sm_csv.loc[i,'comp1']]['index']\n",
    "    b=node[sm_csv.loc[i,'comp2']]['index']\n",
    "    w=sm_csv.loc[i,'w']\n",
    "    if a!=b:\n",
    "        sm[a,b]=w\n",
    "        sm[b,a]=w\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm=sp.csr_matrix(sm)\n",
    "sp.save_npz('./data_preprocessing/comp_relations/sdse.npz',sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "\n",
    "rpt=sp.load_npz('./data_preprocessing/comp_relations/rpt.npz')\n",
    "sc=sp.load_npz('./data_preprocessing/comp_relations/sc.npz')\n",
    "sdse=sp.load_npz('./data_preprocessing/comp_relations/sameManager.npz')\n",
    "sdse2=sp.load_npz('./data_preprocessing/comp_relations/sdse_sameyear.npz')\n",
    "adj_matrix=sdse\n",
    "#adj_matrix2=sp.load_npz('./data_preprocessing/RT_SC_B_v3.npz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdse[0,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdse2[0,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "node_num=len(features)\n",
    "kf=KFold(5,shuffle=True,random_state=5)\n",
    "val_auc=[]\n",
    "test_auc=[]\n",
    "parmas=[]\n",
    "leanring_rate=[0.1,0.01,0.05]\n",
    "l2=[0.0001,0.001,0]\n",
    "weight=[[1.0,1.0],[1.0,2.0],[1.0,3.0],[1.0,4.0]]\n",
    "for l in l2:\n",
    "    for w in weight:\n",
    "        for lr in leanring_rate:\n",
    "            parmas.append([lr,w,l])\n",
    "k=0\n",
    "for train_ids,test_ids in kf.split(features,groups=financial_featrues['label'].values):\n",
    "    print('==========={}============'.format(k))\n",
    "    train_mask_row=sample_mask(train_ids,node_num)\n",
    "    train_ids,val_ids=train_test_split(train_ids,test_size=0.25,stratify=financial_featrues['label'].values[train_ids],random_state=5)\n",
    "    test_mask = sample_mask(test_ids, node_num)\n",
    "    train_mask = sample_mask(train_ids, node_num)\n",
    "    val_mask = sample_mask(val_ids, node_num)\n",
    "    test_mask = sample_mask(test_ids, node_num)\n",
    "    val_auc_tmp=[]\n",
    "\n",
    "    re=[]\n",
    "    for p in tqdm(parmas):\n",
    "        gcn=myGCN(print_flag=False)\n",
    "        best_e,best_val_auc,_=gcn.fit(adj,features,train_mask,val_mask,learning_rate=p[0],epochs=4000,weight=p[1],l2_ratio=p[2])\n",
    "        re.append([best_e,best_val_auc])\n",
    "    best_id=np.argmax([i[1] for i in re])\n",
    "    print('best params{},best epoch:{},best val auc:{}'.format(parmas[best_id],re[best_id][0],re[best_id][1]))\n",
    "    val_auc.append(re[best_id][1])\n",
    "    gcn=myGCN(print_flag=False,early_stopping=False)\n",
    "    best_e,_,best_test_auc=gcn.fit(adj,features,train_mask_row,test_mask,learning_rate=parmas[best_id][0],epochs=re[best_id][0],weight=parmas[best_id][1],l2_ratio=parmas[best_id][2])\n",
    "    print('test auc:{}'.format(best_test_auc))\n",
    "    test_auc.append(best_test_auc)\n",
    "print('val auc average:{}'.format(np.mean(val_auc)))\n",
    "print('test auc average:{}'.format(np.mean(test_auc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RPT+the same company 网络\n",
    "\n",
    "===========0============\n",
    "100%|██████████| 36/36 [1:00:22<00:00, 100.62s/it]\n",
    "best params[0.05, [1.0, 2.0], 0.0001],best epoch:1727,best val auc:0.6852137182902536\n",
    "test auc:0.6926411368201484\n",
    "===========0============\n",
    "100%|██████████| 36/36 [47:57<00:00, 79.93s/it]  \n",
    "best params[0.05, [1.0, 1.0], 0],best epoch:2775,best val auc:0.6710227814317035\n",
    "test auc:0.6467137020990366\n",
    "===========0============\n",
    "100%|██████████| 36/36 [46:46<00:00, 77.95s/it]  \n",
    "best params[0.05, [1.0, 3.0], 0.0001],best epoch:2227,best val auc:0.6728140372880309\n",
    "test auc:0.6637855387855389\n",
    "===========0============\n",
    "100%|██████████| 36/36 [57:31<00:00, 95.88s/it]  \n",
    "best params[0.05, [1.0, 1.0], 0],best epoch:1807,best val auc:0.6871306316678178\n",
    "test auc:0.6733896683673469\n",
    "===========0============\n",
    "100%|██████████| 36/36 [47:11<00:00, 78.66s/it]  \n",
    "best params[0.05, [1.0, 1.0], 0.0001],best epoch:1610,best val auc:0.693710488716654\n",
    "test auc:0.63747542693609\n",
    "val auc average:0.6819783314788921\n",
    "test auc average:0.6628010946016321\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "node_num=len(features)\n",
    "parmas=[]\n",
    "dim=[1000]\n",
    "l2=[0.01]\n",
    "weight=[[1.0,2.0],[1.0,4.0],[1.0,8.0]]\n",
    "dropout=[0.2,0.4,0.6]\n",
    "iter=itertools.product(dim,weight,l2,dropout)\n",
    "train_ids,test_ids=train_test_split(np.array(range(len(features))),stratify=financial_featrues['label'].values,random_state=5,test_size=0.2)\n",
    "train_mask_row=sample_mask(train_ids,node_num)\n",
    "train_ids,val_ids=train_test_split(train_ids,test_size=0.25,stratify=financial_featrues['label'].values[train_ids],random_state=5)\n",
    "test_mask = sample_mask(test_ids, node_num)\n",
    "train_mask = sample_mask(train_ids, node_num)\n",
    "val_mask = sample_mask(val_ids, node_num)\n",
    "test_mask = sample_mask(test_ids, node_num)\n",
    "val_auc_tmp=[]\n",
    "re=[]\n",
    "for p in iter:\n",
    "    parmas.append(p)\n",
    "    print(p)\n",
    "    gcn=myGCN(print_flag=False,early_stopping=True)\n",
    "    loss_history,train_auc_history,val_auc_history,test_auc_history,best_e,best_val_auc=gcn.fit(adj,features,labels,train_mask,val_mask,test_mask,learning_rate=0.0001,epochs=4000,\n",
    "        weight=p[1],l2_ratio=p[2],dropout=p[3],tolerance=500,min_epoch=300,embed_dim=p[0])\n",
    "    re.append([best_e,best_val_auc,test_auc_history[best_e]])\n",
    "    print('best epoch {}, val auc:{}'.format(best_e,best_val_auc))\n",
    "best_id=np.argmax([i[1] for i in re])\n",
    "print('best params{},best epoch:{},best val auc:{},test auc:{}'.format(parmas[best_id],re[best_id][0],re[best_id][1],re[best_id][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with kg\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "node_num=len(features)\n",
    "parmas=[]\n",
    "dim=[1000]\n",
    "l2=[0.01]\n",
    "weight=[[1.0,2.0],[1.0,4.0],[1.0,8.0]]\n",
    "dropout=[0.2,0.4,0.6]\n",
    "iter=itertools.product(dim,weight,l2,dropout)\n",
    "train_ids,test_ids=train_test_split(np.array(range(len(features))),stratify=financial_featrues['label'].values,random_state=5,test_size=0.2)\n",
    "train_mask_row=sample_mask(train_ids,node_num)\n",
    "train_ids,val_ids=train_test_split(train_ids,test_size=0.25,stratify=financial_featrues['label'].values[train_ids],random_state=5)\n",
    "test_mask = sample_mask(test_ids, node_num)\n",
    "train_mask = sample_mask(train_ids, node_num)\n",
    "val_mask = sample_mask(val_ids, node_num)\n",
    "test_mask = sample_mask(test_ids, node_num)\n",
    "val_auc_tmp=[]\n",
    "re=[]\n",
    "for p in iter:\n",
    "    parmas.append(p)\n",
    "    print(p)\n",
    "    gcn=myGCN(print_flag=False,early_stopping=True)\n",
    "    loss_history,train_auc_history,val_auc_history,test_auc_history,best_e,best_val_auc=gcn.fit(adj,features,labels,train_mask,val_mask,test_mask,learning_rate=0.0001,epochs=4000,\n",
    "        weight=p[1],l2_ratio=p[2],dropout=p[3],tolerance=500,min_epoch=300,embed_dim=p[0])\n",
    "    re.append([best_e,best_val_auc,test_auc_history[best_e]])\n",
    "    print('best epoch {}, val auc:{}'.format(best_e,best_val_auc))\n",
    "best_id=np.argmax([i[1] for i in re])\n",
    "print('best params{},best epoch:{},best val auc:{},test auc:{}'.format(parmas[best_id],re[best_id][0],re[best_id][1],re[best_id][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params(1000, [1.0, 8.0], 0.01, 0.4),best epoch:567,best val auc:0.7760073919408644,test auc:0.7715912579630055\n"
     ]
    }
   ],
   "source": [
    "best_id=np.argmax([i[1] for i in re])\n",
    "print('best params{},best epoch:{},best val auc:{},test auc:{}'.format(parmas[best_id],re[best_id][0],re[best_id][1],re[best_id][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params(0.0001, [1.0, 2.0], 0.001, 0.2),best epoch:504,best val auc:0.7447452420380637\n",
      "True\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print('best params{},best epoch:{},best val auc:{}'.format(parmas[best_id],re[best_id][0],re[best_id][1]))\n",
    "gcn=myGCN(print_flag=False,early_stopping=False)\n",
    "_,_,test_auc,_=gcn.fit(adj,features,labels,train_mask,test_mask,learning_rate=parmas[best_id][0],epochs=re[best_id][0],weight=parmas[best_id][1],\n",
    "    l2_ratio=parmas[best_id][2],dropout=parmas[best_id][3],min_epoch=0,max_train_auc=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda:0\n",
      "test auc:0.6946307276076445\n"
     ]
    }
   ],
   "source": [
    "gcn=myGCN(print_flag=False,early_stopping=False)\n",
    "best_id=np.argmax([i[1] for i in re])\n",
    "_,_,test_auc,_=gcn.fit(adj,features,labels,train_mask,test_mask,learning_rate=parmas[best_id][0],epochs=re[best_id][0],weight=parmas[best_id][1],l2_ratio=parmas[best_id][2],min_epoch=0)\n",
    "print('test auc:{}'.format(test_auc[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===previous year,RT_SC_B_V2\n",
    "\n",
    "\n",
    "**best params(0.0001, [1.0, 6.0], 0.01, 0.5),best epoch:1415,best val auc:0.7538483692130463,test auc:0.751702931921099**\n",
    "\n",
    "new npz:\n",
    "best params(0.0001, [1.0, 2.0], 0.01, 0.4),best epoch:1804,best val auc:0.749967600259198,test auc:0.738921348530202\n",
    "emd dim=1500,best params(0.0001, [1.0, 8.0], 0.01, 0.2),best epoch:848,best val auc:0.7751529987760097,test auc:0.7724451224192186\n",
    "\n",
    "---\n",
    "\n",
    "===RT_SC_B_V2_withkg4\n",
    "\n",
    "**best params(0.0001, [1.0, 4.0], 0.001, 0.3),best epoch:1655,best val auc:0.758,test auc:0.755**\n",
    "\n",
    "new npz:\n",
    "params[0.0001, [1.0, 6.0], 0.01, 0.5, 0.97, 0.95], epoch:869,best val auc:0.7522139822881416,test auc:0.7415213178294574\n",
    "KG4_1:params[0.0001, [1.0, 6.0], 0.001, 0.3, 0.99, 0.9], epoch:587,best val auc:0.7687930496556028,test auc:0.7757550464348761\n",
    "\n",
    "KG4_3:embed dim=2000,best params(0.0001, [1.0, 8.0], 0.01, 0.4),best epoch:622,best val auc:0.7797801617587059,test auc:0.7638441169698366\n",
    "\n",
    "===RPT+SC\n",
    "best params(0.0001, [1.0, 2.0], 0.01, 0.6),best epoch:837,best val auc:0.7237538099695203,test auc:0.7222733901297106\n",
    "f1:0.32980972515856233,recall:0.3023255813953488,precision:0.3627906976744186\n",
    "\n",
    "===SDSE+SC(same year sdse)\n",
    "best params(0.0001, [1.0, 8.0], 0.01, 0.6),best epoch:1462,best val auc:0.7297525619795042,test auc:0.7048483191342391\n",
    "f1:0.3660287081339713,recall:0.5930232558139535,precision:0.2647058823529412\n",
    "\n",
    "===SDSE+SC(all year sdse)\n",
    "params[0.0001, [1.0, 8.0], 0.01, 0.6, 0.99, 0.5], epoch:1072,best val auc:0.7654642762857896,test auc:0.7636042674034846\n",
    "f1:0.41450777202072536,recall:0.6201550387596899,precision:0.311284046692607\n",
    "\n",
    "#params[0.0001, [1.0, 8.0], 0.2, 0.6, 0.99, 0.5], epoch:889,best val auc:0.772,test auc:0.777429\n",
    "\n",
    "===RPT+SDSE\n",
    "params[0.0001, [1.0, 6.0], 0.01, 0.2, 0.99, 0.9], epoch:842,best val auc:0.7729402164782682,test auc:0.7698187696676645\n",
    "f1:0.4455284552845529,recall:0.5310077519379846,precision:0.38375350140056025\n",
    "\n",
    "===RPT+SDSE+SC+KG\n",
    "complex kg5_3\n",
    "**dim=1000,best params(1000, [1.0, 6.0], 0.01, 0.5),best epoch:1027,best val auc:0.7768857849137206,test auc:0.7760116854708726**\n",
    "f1:0.44791667,recall:0.5,precision:0.40566 (0.55)\n",
    "complex kg5_2\n",
    "best params(1500, [1.0, 6.0], 0.01, 0.5),best epoch:1020,best val auc:0.7799025607795138,test auc:0.7740449190267864\n",
    "\n",
    "===RPT+SDSE+SC\n",
    "**best params(0.0001, [1.0, 2.0], 0.01, 0.2),best epoch:951,best val auc:0.7744354045167638,test auc:0.7731478816486299**\n",
    "f1:0.444,recall:0.43023255813953487,precision:0.45867768595041325\n",
    "\n",
    "===SDSE+KG\n",
    "KG5_3\n",
    "best params(1000, [1.0, 4.0], 0.01, 0.4),best epoch:568,best val auc:0.7716610267117864,test auc:0.7640168086576099\n",
    "\n",
    "===SDSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G=nx.from_scipy_sparse_matrix(adj_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374.64 25 [9314, 19, 1, 2, 1, 1, 1, 4, 1, 3, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "cc_len=[]\n",
    "for cc in nx.connected_components(G):\n",
    "    cc_len.append(len(cc))\n",
    "print(np.average(cc_len),len(cc_len),cc_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0001, [1.0, 6.0], 0.01, 0.5, 0.99, 0.9]\n",
      "True\n",
      "cuda:0\n",
      "Epoch 000: Loss 0.7117, TrainAuc 0.5006, ValAuc 0.5606\n",
      "Epoch 100: Loss 0.6803, TrainAuc 0.5953, ValAuc 0.6578\n",
      "Epoch 200: Loss 0.6540, TrainAuc 0.6588, ValAuc 0.6843\n",
      "Epoch 300: Loss 0.5874, TrainAuc 0.7562, ValAuc 0.7405\n",
      "Epoch 400: Loss 0.4864, TrainAuc 0.8497, ValAuc 0.7569\n",
      "epoch 467 meet the min train auc requirement\n",
      "Epoch 500: Loss 0.3912, TrainAuc 0.9125, ValAuc 0.7618\n",
      "Epoch 600: Loss 0.3128, TrainAuc 0.939, ValAuc 0.7648\n",
      "Epoch 700: Loss 0.2716, TrainAuc 0.9563, ValAuc 0.7658\n",
      "Epoch 800: Loss 0.2464, TrainAuc 0.9643, ValAuc 0.7635\n",
      "Epoch 900: Loss 0.2107, TrainAuc 0.9711, ValAuc 0.7636\n",
      "Epoch 1000: Loss 0.1978, TrainAuc 0.9745, ValAuc 0.7676\n",
      " params[0.0001, [1.0, 6.0], 0.01, 0.5, 0.99, 0.9], epoch:830,best val auc:0.7702210382316942,test auc:0.7730351523524446\n"
     ]
    }
   ],
   "source": [
    "#手动\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "node_num=len(features)\n",
    "train_ids,test_ids=train_test_split(np.array(range(len(features))),stratify=financial_featrues['label'].values,random_state=5,test_size=0.2)\n",
    "train_mask_row=sample_mask(train_ids,node_num)\n",
    "\n",
    "train_ids,val_ids=train_test_split(train_ids,test_size=0.25,stratify=financial_featrues['label'].values[train_ids],random_state=5)\n",
    "test_mask = sample_mask(test_ids, node_num)\n",
    "train_mask = sample_mask(train_ids, node_num)\n",
    "val_mask = sample_mask(val_ids, node_num)\n",
    "# lr,weight,l2_ratio,dropout\n",
    "p=[0.0001,[1.0,6.0],0.01,0.5,0.99,0.90]\n",
    "print(p)\n",
    "gcn=myGCN(print_flag=True,early_stopping=False)\n",
    "loss_history,train_auc_history,val_auc_history,test_auc_history,best_e,best_val_auc=gcn.fit(adj,features,labels,train_mask,val_mask,test_mask,learning_rate=p[0],epochs=1027,weight=p[1],\n",
    "    l2_ratio=p[2],dropout=p[3],min_epoch=500,max_train_auc=p[4],min_train_auc=p[5],tolerance=500,embed_dim=1000)\n",
    "print(' params{}, epoch:{},best val auc:{},test auc:{}'.format(p,best_e,best_val_auc,test_auc_history[best_e-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc,logit,y=gcn.test(test_mask,drop_out=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_y=[0 if logit[i,0]>logit[i,1] else 1 for i in range(len(logit))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1:0.4455284552845529,recall:0.5310077519379846,precision:0.38375350140056025\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "def Find_Optimal_Cutoff(TPR, FPR, threshold):\n",
    "    y = TPR - FPR\n",
    "    Youden_index = np.argmax(y)  # Only the first occurrence is returned.\n",
    "    optimal_threshold = threshold[Youden_index]\n",
    "    point = [FPR[Youden_index], TPR[Youden_index]]\n",
    "    return optimal_threshold, point\n",
    "\n",
    "\n",
    "y_pred=predict_y\n",
    "f1=metrics.f1_score(y,y_pred)\n",
    "recall=metrics.recall_score(y,y_pred)\n",
    "precision=metrics.precision_score(y,y_pred)\n",
    "print('f1:{},recall:{},precision:{}'.format(f1,recall,precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0001, [1.0, 8.0], 0.01, 0.4, 0.99, 0.9]\n",
      "True\n",
      "cuda:0\n",
      "Epoch 000: Loss 0.7156, TrainAuc 0.5114, ValAuc 0.5579\n",
      "Epoch 100: Loss 0.6662, TrainAuc 0.617, ValAuc 0.6613\n",
      "Epoch 200: Loss 0.6254, TrainAuc 0.7038, ValAuc 0.7185\n",
      "Epoch 300: Loss 0.5333, TrainAuc 0.8177, ValAuc 0.7551\n",
      "epoch 384 meet the min train auc requirement\n",
      "Epoch 400: Loss 0.3940, TrainAuc 0.9014, ValAuc 0.7650\n",
      "Epoch 500: Loss 0.2898, TrainAuc 0.9538, ValAuc 0.7686\n",
      "Epoch 600: Loss 0.2167, TrainAuc 0.9691, ValAuc 0.7701\n",
      "Epoch 700: Loss 0.2025, TrainAuc 0.9786, ValAuc 0.7632\n",
      "Epoch 800: Loss 0.1740, TrainAuc 0.9845, ValAuc 0.7675\n",
      "Epoch 900: Loss 0.1658, TrainAuc 0.9891, ValAuc 0.7678\n",
      "train auc meets the setting line:0.99\n",
      " params[0.0001, [1.0, 8.0], 0.01, 0.4, 0.99, 0.9], epoch:512,best val auc:0.7749010007919938,test auc:0.7703608296876199\n"
     ]
    }
   ],
   "source": [
    "#手动\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "node_num=len(features)\n",
    "train_ids,test_ids=train_test_split(np.array(range(len(features))),stratify=financial_featrues['label'].values,random_state=5,test_size=0.2)\n",
    "train_mask_row=sample_mask(train_ids,node_num)\n",
    "\n",
    "train_ids,val_ids=train_test_split(train_ids,test_size=0.25,stratify=financial_featrues['label'].values[train_ids],random_state=5)\n",
    "test_mask = sample_mask(test_ids, node_num)\n",
    "train_mask = sample_mask(train_ids, node_num)\n",
    "val_mask = sample_mask(val_ids, node_num)\n",
    "# lr,weight,l2_ratio,dropout\n",
    "p=[0.0001,[1.0,8.0],0.01,0.4,0.99,0.90]\n",
    "print(p)\n",
    "gcn=myGCN(print_flag=True,early_stopping=True)\n",
    "loss_history,train_auc_history2,val_auc_history2,test_auc_history2,best_e2,best_val_auc2=gcn.fit(adj,features,labels,train_mask,val_mask,test_mask,learning_rate=p[0],epochs=3000,weight=p[1],\n",
    "    l2_ratio=p[2],dropout=p[3],min_epoch=500,max_train_auc=p[4],min_train_auc=p[5],tolerance=500,embed_dim=1200)\n",
    "print(' params{}, epoch:{},best val auc:{},test auc:{}'.format(p,best_e,best_val_auc2,test_auc_history2[best_e2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " params[0.0002, [1.0, 6.0], 0, 0.5, 0.97, 0.95], epoch:830,best val auc:0.6975808193534452,test auc:0.7102425358814951\n"
     ]
    }
   ],
   "source": [
    "print(' params{}, epoch:{},best val auc:{},test auc:{}'.format(p,best_e,best_val_auc,test_auc_history[best_e]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda:0\n",
      "epoch 0 meet the min train auc requirement\n",
      "epoch 1 meet the min train auc requirement\n",
      "finished\n",
      "test auc:0.7362158454217516\n"
     ]
    }
   ],
   "source": [
    "gcn=myGCN(print_flag=False,early_stopping=False)\n",
    "best_e=1570\n",
    "_,_,test_auc,_,_=gcn.fit(adj,features,labels,train_mask,test_mask,learning_rate=p[0],epochs=best_e,weight=p[1],l2_ratio=p[2],dropout=p[3],min_epoch=0,max_train_auc=1,min_train_auc=0,embed_dim=1024)\n",
    "print('finished')\n",
    "print('test auc:{}'.format(test_auc[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "withKG_train_auc_curve=train_auc_history\n",
    "withKG_val_auc_curve=val_auc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn=myGCN(print_flag=False,early_stopping=False)\n",
    "best_e=len(val_auc_history)\n",
    "_,_,test_auc,_=gcn.fit(adj,features,labels,train_mask,test_mask,learning_rate=p[0],epochs=best_e,weight=p[1],l2_ratio=p[2],dropout=p[3],min_epoch=0,max_train_auc=1)\n",
    "\n",
    "print('test auc:{}'.format(test_auc[-1]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x251e9696908>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.plot(range(len(train_auc_history)),train_auc_history,'b-',label='train auc')\n",
    "ax1.plot(range(len(val_auc_history)),val_auc_history,'r-',label='val auc')\n",
    "ax1.plot(test_auc_history)\n",
    "ax1.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda:0\n",
      "Epoch 000: Loss 0.7345, TrainAuc 0.5086, ValAuc 0.5034\n",
      "Epoch 050: Loss 0.6636, TrainAuc 0.6334, ValAuc 0.6154\n",
      "Epoch 100: Loss 0.6309, TrainAuc 0.6999, ValAuc 0.6615\n",
      "Epoch 150: Loss 0.6046, TrainAuc 0.7461, ValAuc 0.6836\n",
      "Epoch 200: Loss 0.5811, TrainAuc 0.774, ValAuc 0.6902\n",
      "Epoch 250: Loss 0.5622, TrainAuc 0.7979, ValAuc 0.6954\n",
      "Epoch 300: Loss 0.5377, TrainAuc 0.8196, ValAuc 0.7006\n",
      "Epoch 350: Loss 0.5353, TrainAuc 0.8377, ValAuc 0.7023\n",
      "Epoch 400: Loss 0.5024, TrainAuc 0.8546, ValAuc 0.7057\n",
      "Epoch 450: Loss 0.4643, TrainAuc 0.8698, ValAuc 0.7093\n",
      "Epoch 500: Loss 0.4764, TrainAuc 0.8808, ValAuc 0.7141\n",
      "test auc:0.7145622265714944\n"
     ]
    }
   ],
   "source": [
    "gcn=myGCN(print_flag=True,early_stopping=False)\n",
    "_,_,test_auc,_=gcn.fit(adj,features,labels,train_mask,test_mask,learning_rate=p[0],epochs=best_e,weight=p[1],l2_ratio=p[2],dropout=p[3],min_epoch=0,max_train_auc=1)\n",
    "\n",
    "print('test auc:{}'.format(test_auc[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading {} dataset...\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('./new/RT_SC_B_v2_withKG.csv')\n",
    "y=data.iloc[:,-1]\n",
    "X=data.iloc[:,0:-1]\n",
    "for column in list(X.columns[X.isna().sum() > 0]):\n",
    "    mean_val = X[column].mean()\n",
    "    X[column].fillna(mean_val, inplace=True)\n",
    "adj_matrix=sp.load_npz('./new/RT_SC_B_v2.npz')\n",
    "X=X.values\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "X=minmax_scale(X)\n",
    "y=financial_featrues['label'].values\n",
    "adj, features, labels=load_data(X,y,adj_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0001, [1.0, 8.0], 0.001, 0.2)\n",
      "True\n",
      "cuda:0\n",
      "(0.0001, [1.0, 8.0], 0.001, 0.1)\n",
      "True\n",
      "cuda:0\n",
      "(0.0001, [1.0, 6.0], 0.001, 0.2)\n",
      "True\n",
      "cuda:0\n",
      "(0.0001, [1.0, 6.0], 0.001, 0.1)\n",
      "True\n",
      "cuda:0\n",
      "(0.0001, [1.0, 4.0], 0.001, 0.2)\n",
      "True\n",
      "cuda:0\n",
      "(0.0001, [1.0, 4.0], 0.001, 0.1)\n",
      "True\n",
      "cuda:0\n",
      "(0.0001, [1.0, 2.0], 0.001, 0.2)\n",
      "True\n",
      "cuda:0\n",
      "(0.0001, [1.0, 2.0], 0.001, 0.1)\n",
      "True\n",
      "cuda:0\n",
      "best params(0.0001, [1.0, 4.0], 0.001, 0.1),best epoch:508,best val auc:0.7408620731034151\n",
      "True\n",
      "cuda:0\n",
      "test auc:0.7218800368408933\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "node_num=len(features)\n",
    "parmas=[]\n",
    "leanring_rate=[0.0001]\n",
    "l2=[0.001]\n",
    "weight=[[1.0,8.0],[1.0,6.0],[1.0,4.0],[1.0,2.0]]\n",
    "dropout=[0.2,0.1]\n",
    "iter=itertools.product(leanring_rate,weight,l2,dropout)\n",
    "train_ids,test_ids=train_test_split(np.array(range(len(features))),stratify=financial_featrues['label'].values,random_state=5,test_size=0.2)\n",
    "train_mask_row=sample_mask(train_ids,node_num)\n",
    "train_ids,val_ids=train_test_split(train_ids,test_size=0.25,stratify=financial_featrues['label'].values[train_ids],random_state=5)\n",
    "test_mask = sample_mask(test_ids, node_num)\n",
    "train_mask = sample_mask(train_ids, node_num)\n",
    "val_mask = sample_mask(val_ids, node_num)\n",
    "test_mask = sample_mask(test_ids, node_num)\n",
    "val_auc_tmp=[]\n",
    "re=[]\n",
    "for p in iter:\n",
    "    parmas.append(p)\n",
    "    print(p)\n",
    "    gcn=myGCN(print_flag=False,early_stopping=True)\n",
    "    loss_history,train_auc_history,val_auc_history,best_e=gcn.fit(adj,features,labels,train_mask,val_mask,learning_rate=p[0],epochs=4000,\n",
    "        weight=p[1],l2_ratio=p[2],dropout=p[3],min_epoch=500,max_train_auc=1.0,tolerance=400)\n",
    "    re.append([best_e,max(val_auc_history)])\n",
    "best_id=np.argmax([i[1] for i in re])\n",
    "print('best params{},best epoch:{},best val auc:{}'.format(parmas[best_id],re[best_id][0],re[best_id][1]))\n",
    "gcn=myGCN(print_flag=False,early_stopping=False)\n",
    "_,_,test_auc,_=gcn.fit(adj,features,labels,train_mask,test_mask,learning_rate=parmas[best_id][0],epochs=re[best_id][0],weight=parmas[best_id][1],\n",
    "    l2_ratio=parmas[best_id][2],dropout=parmas[best_id][3],min_epoch=0,max_train_auc=1.0)\n",
    "print('test auc:{}'.format(test_auc[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "class GraphConvolution(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, use_bias=True):\n",
    "        \"\"\"图卷积：L*X*\\theta\n",
    "        Args:\n",
    "        ----------\n",
    "            input_dim: int\n",
    "                节点输入特征的维度\n",
    "            output_dim: int\n",
    "                输出特征维度\n",
    "            use_bias : bool, optional\n",
    "                是否使用偏置\n",
    "        \"\"\"\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.use_bias = use_bias\n",
    "        self.weight = nn.Parameter(torch.Tensor(input_dim, output_dim))\n",
    "        if self.use_bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(output_dim))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        init.kaiming_uniform_(self.weight)\n",
    "        if self.use_bias:\n",
    "            init.zeros_(self.bias)\n",
    "\n",
    "    def forward(self, adjacency,weight, input_feature):\n",
    "        \"\"\"邻接矩阵是稀疏矩阵，因此在计算时使用稀疏矩阵乘法\n",
    "    \n",
    "        Args: \n",
    "        -------\n",
    "            adjacency: torch.sparse.FloatTensor\n",
    "                邻接矩阵\n",
    "            input_feature: torch.Tensor\n",
    "                输入特征\n",
    "        \"\"\"\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        k=0\n",
    "        weight=weight/weight.sum()\n",
    "        for adj in adjacency:\n",
    "            support = torch.mm(input_feature, self.weight.to(device))\n",
    "            output = torch.sparse.mm(adj, support)\n",
    "            if self.use_bias:\n",
    "                output += self.bias.to(device)\n",
    "            if k==0:\n",
    "                real_output=output*weight[k]\n",
    "            else:\n",
    "                real_output+=output*weight[k]\n",
    "\n",
    "        return real_output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' + str(self.in_features) + ' -> ' + str(self.out_features) + ')'\n",
    "\n",
    "# ## 模型定义\n",
    "class GcnNet2(nn.Module):\n",
    "    \"\"\"\n",
    "    定义一个包含两层GraphConvolution的模型\n",
    "    \"\"\"\n",
    "    def __init__(self, adj_list,input_dim=343,embed_dim=1024):\n",
    "        super(GcnNet2, self).__init__()\n",
    "        self.gcn1 = GraphConvolution(input_dim, embed_dim)\n",
    "        self.gcn2 = GraphConvolution(embed_dim, embed_dim)\n",
    "        self.mlp=nn.Linear(embed_dim,embed_dim)\n",
    "        self.output=nn.Linear(embed_dim,2)\n",
    "        self.adj_list=adj_list\n",
    "        self.adj_weight=nn.Parameter(torch.Tensor(len(adj_list)))\n",
    "        nn.init.constant_(self.adj_weight,1.0)\n",
    "        self.layer_norm=nn.LayerNorm(normalized_shape= embed_dim)\n",
    "    def forward(self, feature,drop_out=0.5):\n",
    "        self.dropout = nn.Dropout(p=drop_out)\n",
    "        h1 = F.relu(self.dropout(self.gcn1(self.adj_list,self.adj_weight, feature)))\n",
    "        h2 = F.relu(self.dropout(self.gcn2(self.adj_list,self.adj_weight, h1)))\n",
    "        h2=self.layer_norm(h2)\n",
    "        h3=torch.sigmoid(self.dropout(self.mlp(h2)))\n",
    "        logits=self.output(h3)\n",
    "        return logits\n",
    "    def get_adj_weight(self):\n",
    "        print(self.adj_weight)\n",
    "        return self.adj_weight\n",
    "from sklearn.metrics import roc_auc_score\n",
    "class myGCN2:\n",
    "    def __init__(self,print_flag=False,early_stopping=True,seed=55):\n",
    "        self.printFlag=print_flag\n",
    "        self.early_stopping=early_stopping\n",
    "        flag = torch.cuda.is_available()\n",
    "        print(flag)\n",
    "        ngpu= 1\n",
    "        # Decide which device we want to run on\n",
    "        self.device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "        print(self.device)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        pass\n",
    "    def fit(self,adj_list,features,labels,train_mask,val_mask,test_mask,learning_rate=0.01,epochs=2000,weight=[1.0,2.0],l2_ratio=0.001,\n",
    "                dropout=0.2,min_epoch=1000,max_train_auc=0.99,min_train_auc=0.90,tolerance=200,embed_dim=1024):\n",
    "        weight_decay = l2_ratio\n",
    "        sample_size=features.size()[0]\n",
    "        feature_size=features.size()[1]\n",
    "        # 模型定义：Model, Loss, Optimizer\n",
    "        device = self.device\n",
    "       \n",
    "        self.dropout=dropout\n",
    "        self.tensor_x = features.to(device)\n",
    "        self.tensor_y = labels.to(device)\n",
    "        tensor_train_mask = torch.from_numpy(train_mask).to(device)\n",
    "        tensor_test_mask = torch.from_numpy(test_mask).to(device)\n",
    "        tensor_val_mask=torch.from_numpy(val_mask).to(device)\n",
    "        self.tensor_adjacency_list=[]\n",
    "        for adj in adj_list:\n",
    "            indices = torch.from_numpy(np.asarray([adj.row, adj.col]).astype('int64')).long()\n",
    "            values = torch.from_numpy(adj.data.astype(np.float32))\n",
    "            \n",
    "            self.tensor_adjacency_list.append(torch.sparse.FloatTensor(indices, values, (sample_size,sample_size)).to(device))\n",
    "        self.model = GcnNet2(self.tensor_adjacency_list,input_dim=feature_size,embed_dim=embed_dim).to(device)\n",
    "        self.criterion = torch.nn.CrossEntropyLoss(weight=torch.tensor(weight,requires_grad=False).to(device))\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        ###train\n",
    "        train_loss,train_auc,val_auc,test_auc,best_e,best_val_auc=self.train(tensor_train_mask,tensor_val_mask,tensor_test_mask,epochs,min_epoch,max_train_auc,min_train_auc,tolerance)\n",
    "        return train_loss,train_auc,val_auc,test_auc,best_e,best_val_auc\n",
    "    def train(self,tensor_train_mask,tensor_val_mask,tensor_test_mask,epochs,min_epoch=1000,max_train_auc=0.98,min_train_auc=0.95,tolerance=200):\n",
    "        loss_history = []\n",
    "        val_auc_history = []\n",
    "        train_auc_history=[]\n",
    "        test_auc_history=[]\n",
    "        self.model.train()\n",
    "        train_y = self.tensor_y[tensor_train_mask]\n",
    "        stop_increasing=0\n",
    "        max_auc=0\n",
    "        train_auc_min_id=0\n",
    "        for epoch in range(epochs):\n",
    "            logits = self.model( self.tensor_x,drop_out=self.dropout)  # 前向传播\n",
    "            train_mask_logits = logits[tensor_train_mask]   # 只选择训练节点进行监督\n",
    "            loss = self.criterion(train_mask_logits, train_y)    # 计算损失值\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()     # 反向传播计算参数的梯度\n",
    "            self.optimizer.step()    # 使用优化方法进行梯度更新\n",
    "            train_acc, _, _ = self.test(tensor_train_mask,drop_out=self.dropout)     # 计算当前模型训练集上的准确率\n",
    "            val_acc, _, _ = self.test(tensor_val_mask,drop_out=0.0)     # 计算当前模型在验证集上的准确率\n",
    "            test_acc, _, _ = self.test(tensor_test_mask,drop_out=0.0) \n",
    "            # 记录训练过程中损失值和准确率的变化，用于画图\n",
    "            loss_history.append(loss.item())\n",
    "            val_auc_history.append(val_acc.item())\n",
    "            train_auc_history.append(train_acc.item())\n",
    "            test_auc_history.append(test_acc.item())\n",
    "            if train_acc>min_train_auc and train_auc_min_id==0:\n",
    "                train_auc_min_id=epoch\n",
    "                print('epoch {} meet the min train auc requirement'.format(epoch))\n",
    "            if train_acc>=max_train_auc:\n",
    "                print('train auc meets the setting line:{}'.format(max_train_auc))\n",
    "                break\n",
    "            if epoch>min_epoch and val_acc.item()<max_auc:\n",
    "                stop_increasing+=1\n",
    "            else:\n",
    "                max_auc=val_acc.item()\n",
    "                stop_increasing=0\n",
    "            if self.early_stopping:\n",
    "                if stop_increasing>=tolerance:\n",
    "                    if self.printFlag:\n",
    "                        print('验证集收敛:epoch {}'.format(epoch))\n",
    "                    break\n",
    "            if epoch%100==0 and self.printFlag:\n",
    "                print(\"Epoch {:03d}: Loss {:.4f}, TrainAuc {:.4}, ValAuc {:.4f}\".format(\n",
    "                    epoch, loss.item(), train_acc.item(), val_acc.item()))\n",
    "        if self.early_stopping==True:\n",
    "            best_e=np.argmax(val_auc_history[min_epoch:])+min_epoch+1\n",
    "            best_val_auc=max(val_auc_history[min_epoch:])\n",
    "        else:\n",
    "            best_e=np.argmax(val_auc_history[train_auc_min_id:])+train_auc_min_id+1\n",
    "            best_val_auc=max(val_auc_history[train_auc_min_id:])\n",
    "        self.model.get_adj_weight()\n",
    "        return loss_history,train_auc_history, val_auc_history,test_auc_history,best_e,best_val_auc\n",
    "# 测试函数\n",
    "    def test(self,mask,drop_out=0.1):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(self.tensor_x,drop_out=drop_out)\n",
    "            test_mask_logits = torch.softmax(logits[mask],dim=1)\n",
    "            predict_y = test_mask_logits[:,1]\n",
    "            auc = roc_auc_score(self.tensor_y[mask].cpu().numpy(),predict_y.cpu().numpy())\n",
    "        return auc, test_mask_logits.cpu().numpy(), self.tensor_y[mask].cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_list = [normalize_adj(sp.coo_matrix(adj, dtype=np.float32)) for adj in [rpt,sdse,sc]]\n",
    "node_num=len(features)\n",
    "train_ids,test_ids=train_test_split(np.array(range(len(features))),stratify=financial_featrues['label'].values,random_state=5,test_size=0.2)\n",
    "train_mask_row=sample_mask(train_ids,node_num)\n",
    "\n",
    "train_ids,val_ids=train_test_split(train_ids,test_size=0.25,stratify=financial_featrues['label'].values[train_ids],random_state=5)\n",
    "test_mask = sample_mask(test_ids, node_num)\n",
    "train_mask = sample_mask(train_ids, node_num)\n",
    "val_mask = sample_mask(val_ids, node_num)\n",
    "# lr,weight,l2_ratio,dropout\n",
    "p=[0.0001,[1.0,8.0],0.01,0.6,0.99,0.90]\n",
    "print(p)\n",
    "gcn=myGCN2(print_flag=True,early_stopping=True)\n",
    "loss_history,train_auc_history2,val_auc_history2,test_auc_history2,best_e2,best_val_auc2=gcn.fit(adj_list,features,labels,train_mask,val_mask,test_mask,learning_rate=p[0],epochs=3000,weight=p[1],\n",
    "    l2_ratio=p[2],dropout=p[3],min_epoch=500,max_train_auc=p[4],min_train_auc=p[5],tolerance=500,embed_dim=1200)\n",
    "print(' params{}, epoch:{},best val auc:{},test auc:{}'.format(p,best_e,best_val_auc2,test_auc_history2[best_e2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2469a70536e4d2335a2ea8907942d0699c37342a371ac185bdb5b0aa6f073890"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
