{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violation=pd.read_excel('./STK_Violation_Main.xlsx')\n",
    "financial_featrues=pd.read_excel('./financial_features.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_featrues=financial_featrues.loc[financial_featrues['year']>=2003]\n",
    "violation=violation.loc[violation['IsViolated']=='Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(financial_featrues.index):\n",
    "    code=financial_featrues.loc[i,'Stkcd']\n",
    "    year=financial_featrues.loc[i,'year']\n",
    "    tmp=violation.loc[violation['Stkcd']==code]\n",
    "    tmp['year']=tmp['year'].apply(lambda x:str(x))\n",
    "    if len(tmp)==0:\n",
    "        financial_featrues.loc[i,'label']=0\n",
    "    else:\n",
    "        financial_featrues.loc[i,'label']=0\n",
    "        for j in tmp.index:\n",
    "            if str(year) in tmp.loc[j,'year'].split(','):\n",
    "                financial_featrues.loc[i,'label']=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_featrues['IndustryCode'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_featrues=financial_featrues.loc[financial_featrues['year']<=2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_featrues['IndustryCode'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_featrues.to_csv('financial_features.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a=financial_featrues.isna().sum(axis=1)\n",
    "delete_row=a.index[a.apply(lambda x:x>0.2*349)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_featrues.drop(delete_row,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a=financial_featrues.isna().sum(axis=0)\n",
    "delete_col=a.index[a.apply(lambda x:x>0.2*26710)]\n",
    "financial_featrues.drop(delete_col,inplace=True,axis=1)\n",
    "financial_featrues.to_csv('financial_features.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold,train_test_split\n",
    "import logging\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost\n",
    "from sklearn import metrics\n",
    "class experiment_protocal():\n",
    "    def __init__(self,params_dict,model,exp_name,comment):\n",
    "        self.parmas_dict=params_dict\n",
    "        self.model=model\n",
    "        self.exp_name=exp_name\n",
    "        \n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "        self.logger.setLevel(level = logging.INFO)\n",
    "        handler = logging.FileHandler('./log/'+self.exp_name+'.txt')\n",
    "        handler.setLevel(logging.INFO)\n",
    "        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "        handler.setFormatter(formatter)\n",
    "        self.logger.addHandler(handler)\n",
    "        self.logger.info(comment)\n",
    "        self.logger.info(\"Start print log\")\n",
    "    def cv_train_test_split(self,X,y,cv_num,seed=5):\n",
    "        kf=KFold(n_splits=cv_num,shuffle=True,random_state=seed)\n",
    "        k=0\n",
    "        return kf.split(X,y)\n",
    "    def select_best_model(self,X,y,cv_num=5,seed=5,printFlag=False):\n",
    "        result=[]\n",
    "        k=0\n",
    "        for params in self.parmas_dict:\n",
    "            if self.model=='RF':\n",
    "                clf = RandomForestClassifier(n_estimators=params.get('n_estimators',100),random_state=0,class_weight='balanced',max_depth=params.get('max_depth',10),\\\n",
    "                    min_samples_leaf=params.get('min_sample_leaf',1),n_jobs=-1)\n",
    "                \n",
    "                X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n",
    "                clf.fit(X_train,y_train)\n",
    "                train_auc=metrics.roc_auc_score(y_train,clf.predict_proba(X_train)[:,1])\n",
    "                y_prob=clf.predict_proba(X_test)\n",
    "                y_prob=y_prob[:,1]\n",
    "                auc=metrics.roc_auc_score(y_test,y_prob)\n",
    "                if printFlag:\n",
    "                    print(params)\n",
    "                    print('val auc:{},train auc:{}'.format(auc,train_auc))\n",
    "                result.append(auc)\n",
    "            elif self.model=='XGBoost':\n",
    "                kf=KFold(n_splits=cv_num,random_state=seed,shuffle=True)\n",
    "                auc=[]\n",
    "                for train_index, test_index in kf.split(X,y):\n",
    "                    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "                    X_train, X_test = X[train_index], X[test_index]\n",
    "                    y_train, y_test = y[train_index], y[test_index]\n",
    "                    Dtrain=xgboost.DMatrix(X_train,y_train)\n",
    "                    Dval=xgboost.DMatrix(X_test,y_test)\n",
    "                    model=xgboost.train(params,Dtrain,num_boost_round=2000,early_stopping_rounds=100,evals=[ (Dtrain, 'train'),(Dval, 'eval')],verbose_eval=False)\n",
    "                    y_prob=model.predict(Dval)\n",
    "                    auc.append(metrics.roc_auc_score(y_test,y_prob))\n",
    "                result.append(np.mean(auc))\n",
    "        return self.parmas_dict[np.argmax(result)],max(result)\n",
    "    def run_model(self,X_train,y_train,X_test,y_test,params):\n",
    "        if self.model=='RF':\n",
    "            clf = RandomForestClassifier(n_estimators=params.get('n_estimators',100),random_state=0,class_weight='balanced',max_depth=params.get('max_depth',10),\\\n",
    "                    min_samples_leaf=params.get('min_sample_leaf',1))\n",
    "            clf.fit(X_train,y_train)\n",
    "            y_prob=clf.predict_proba(X_test)\n",
    "            y_prob=y_prob[:,1]\n",
    "            testauc=(metrics.roc_auc_score(y_test,y_prob))\n",
    "            y_prob=clf.predict_proba(X_train)\n",
    "            y_prob=y_prob[:,1]\n",
    "            trainauc=(metrics.roc_auc_score(y_train,y_prob))\n",
    "            return trainauc,testauc\n",
    "        elif self.model=='XGBoost':\n",
    "            Dtrain=xgboost.DMatrix(X_train,y_train)\n",
    "            Dval=xgboost.DMatrix(X_test,y_test)\n",
    "            model=xgboost.train(params,Dtrain,num_boost_round=2000,early_stopping_rounds=100,evals=[ (Dtrain, 'train'),(Dval, 'eval')],verbose_eval=False)\n",
    "            y_prob=model.predict(Dval)\n",
    "            testauc=metrics.roc_auc_score(y_test,y_prob)\n",
    "            y_prob=model.predict(Dtrain)\n",
    "            trainauc=metrics.roc_auc_score(y_train,y_prob)\n",
    "            return trainauc,testauc\n",
    "    def run(self,X,y,cv_num):\n",
    "        split=self.cv_train_test_split(X,y,cv_num)\n",
    "        test_re=[]\n",
    "        val_re=[]\n",
    "        k=0\n",
    "        for train_id,test_id in split:\n",
    "            print('train test split {}'.format(k))\n",
    "            self.logger.info('train test split {}'.format(k))\n",
    "            train_X,test_X,train_y,test_y=X[train_id],X[test_id],y[train_id],y[test_id]\n",
    "            best_params,best_auc=self.select_best_model(train_X,train_y,cv_num=4)\n",
    "            print('best params:{},bets auc on val set:{}'.format(best_params,best_auc))\n",
    "            self.logger.info('best params:{},bets auc on val set:{}'.format(best_params,best_auc))\n",
    "            trainauc,testauc=self.run_model(train_X,train_y,test_X,test_y,best_params)\n",
    "            print('test auc:{}'.format(testauc))\n",
    "            self.logger.info('test auc:{}'.format(testauc))\n",
    "            test_re.append(testauc)\n",
    "            val_re.append(best_auc)\n",
    "            k+=1\n",
    "        self.logger.info('validation set result:{}'.format(val_re))\n",
    "        self.logger.info('test set result:{}'.format(test_re))\n",
    "        logging.shutdown(self.logger)\n",
    "        return test_re,val_re\n",
    "    def simple_run(self,X,y,test_size=0.2,random_state=5):\n",
    "        \"\"\"\n",
    "        return best params, bset validation auc, best test auc\n",
    "        \"\"\"\n",
    "        self.logger.info('simple run with fixed train test split, test size:{}'.format(test_size))\n",
    "        train_X,test_X,train_y,test_y=train_test_split(X,y,stratify=y,test_size=test_size,random_state=random_state)\n",
    "        best_params,best_auc=self.select_best_model(train_X,train_y,printFlag=True)\n",
    "        print('best params:{},bets auc on val set:{}'.format(best_params,best_auc))\n",
    "        self.logger.info('best params:{},bets auc on val set:{}'.format(best_params,best_auc))\n",
    "        trainauc,testauc=self.run_model(train_X,train_y,test_X,test_y,best_params)\n",
    "        print('test auc:{}'.format(testauc))\n",
    "        self.logger.info('test auc:{}'.format(testauc))\n",
    "        logging.shutdown(self.logger)\n",
    "        return best_params,best_auc,testauc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_featrues=pd.read_csv('./financial_features.csv')\n",
    "X=financial_featrues.drop(['year','Stkcd','IndustryCode','label','EquityNatureID'],axis=1)\n",
    "for column in list(X.columns[X.isna().sum() > 0]):\n",
    "    mean_val = X[column].mean()\n",
    "    X[column].fillna(mean_val, inplace=True)\n",
    "\n",
    "X=X.values\n",
    "y=financial_featrues['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "params_dict=[]\n",
    "ne=list(range(2500,5010,250))\n",
    "max_depth=[20,None]\n",
    "min_leaf=[1,5,10]\n",
    "iters=itertools.product(ne,max_depth,min_leaf)\n",
    "for comb in iters:\n",
    "    params_dict.append({'n_estimators':comb[0],'max_depth':comb[1],'min_sample_leaf':comb[2]})\n",
    "print('total len of params comb:{}'.format(len(params_dict)))\n",
    "exp=experiment_protocal(params_dict=params_dict,model='RF',exp_name='baselian_RF',comment='rpt RF baseline')\n",
    "re2=exp.run(X,y,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "baseline RF:\n",
    "\n",
    "test auc:\n",
    "([0.7813094957031855,\n",
    "  0.7592270507665895,\n",
    "  0.7555582320020272,\n",
    "  0.7699949780189731,\n",
    "  0.7611411958097487]\n",
    "  mean:0.765\n",
    "\n",
    "  val auc\n",
    " [0.7658625063984155,\n",
    "  0.7737437110429671,\n",
    "  0.7686943799765285,\n",
    "  0.7656989257542322,\n",
    "  0.7639862635362276])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(re2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpt=pd.read_csv('listed_RPT.csv')\n",
    "financial_featrues=pd.read_csv('financial_features.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28398/28398 [04:48<00:00, 98.60it/s] \n"
     ]
    }
   ],
   "source": [
    "missing=0\n",
    "select_index=[]\n",
    "for i in tqdm(rpt.index):\n",
    "    year=rpt.loc[i,'tradeYear']\n",
    "    cp1=rpt.loc[i,'cp1']\n",
    "    cp2=rpt.loc[i,'cp2']\n",
    "    ind1=financial_featrues.query('Stkcd == @cp1 & year == @year')\n",
    "    ind2=financial_featrues.query('Stkcd == @cp2 & year == @year')\n",
    "    if len(ind1)==0 or len(ind2)==0:\n",
    "        missing+=1\n",
    "        continue\n",
    "    select_index+=[ind1.index.values[0],ind2.index.values[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpt_financial_varibles=financial_featrues.loc[list(set(select_index))]\n",
    "rpt_financial_varibles.to_csv('rpt_fv.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpt_financial_varibles=pd.read_csv('rpt_fv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### baseline for rpt dataset\n",
    "data=pd.read_csv('./RT_SC_B_features.csv')\n",
    "financial_featrues=data\n",
    "X=financial_featrues.drop(['year','Stkcd','IndustryCode','label','EquityNatureID'],axis=1)\n",
    "for column in list(X.columns[X.isna().sum() > 0]):\n",
    "    mean_val = X[column].mean()\n",
    "    X[column].fillna(mean_val, inplace=True)\n",
    "X=X.values\n",
    "y=financial_featrues['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "params_dict=[]\n",
    "ne=list(range(2500,5010,250))\n",
    "max_depth=[20,None]\n",
    "min_leaf=[1,5,10]\n",
    "iters=itertools.product(ne,max_depth,min_leaf)\n",
    "for comb in iters:\n",
    "    params_dict.append({'n_estimators':comb[0],'max_depth':comb[1],'min_sample_leaf':comb[2]})\n",
    "print('total len of params comb:{}'.format(len(params_dict)))\n",
    "exp=experiment_protocal(params_dict=params_dict,model='RF',exp_name='rpt_baseline',comment='baseline with rpt related dataset')\n",
    "re=exp.simple_run(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12048/12048 [03:40<00:00, 54.54it/s]\n"
     ]
    }
   ],
   "source": [
    "triples={}\n",
    "###增加 关联交易（RPT） 关系\n",
    "for i in rpt.index:\n",
    "    \n",
    "    year=str(rpt.loc[i,'tradeYear'])\n",
    "    t=tuple([year+'.comp.'+str(rpt.loc[i,'cp1']),'relatedTransaction',year+'.comp.'+str(rpt.loc[i,'cp2'])])\n",
    "    triples[t]=1\n",
    "from tqdm import tqdm\n",
    "tmpT=np.array([list(i) for i in list(triples.keys())])\n",
    "X=[list(i) for i in list(triples.keys())]\n",
    "###增加 the same company 关系\n",
    "for i in tqdm(range(len(tmpT))):\n",
    "    c1=tmpT[i][0]\n",
    "    c1_n_set=[]\n",
    "    for j in range(len(tmpT)):\n",
    "        \n",
    "        c2=tmpT[j][0]\n",
    "        c3=tmpT[j][2]\n",
    "        if c2!=c1 and c1[4:]==c2[4:]:\n",
    "            t=int(c2[0:4])\n",
    "            if t not in c1_n_set and t<int(c1[0:4]):\n",
    "                \n",
    "                c1_n_set.append(t)\n",
    "        if c3!=c1 and c1[4:]==c3[4:]:\n",
    "            t=int(c3[0:4])\n",
    "            if t not in c1_n_set and t<int(c1[0:4]):\n",
    "                c1_n_set.append(t)\n",
    "    if len(c1_n_set)!=0:\n",
    "        t=[c1,'year.previous',str(max(c1_n_set))+c1[4:]]\n",
    "        if t not in X:\n",
    "            X.append(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X).to_csv('KG3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9366/9366 [00:00<00:00, 40300.68it/s]\n"
     ]
    }
   ],
   "source": [
    "###增加分类类别关系\n",
    "industry_triples=[]\n",
    "for i in tqdm(rpt_financial_varibles.index):\n",
    "    year=rpt_financial_varibles.loc[i,'year']\n",
    "    code=rpt_financial_varibles.loc[i,'Stkcd']\n",
    "    ind='ind.'+str(rpt_financial_varibles.loc[i,'IndustryCode'])\n",
    "    industry_triples.append([str(year)+'.comp.'+str(code),'industry',ind])\n",
    "X+=industry_triples\n",
    "# categories=['Big4','Outside','OneControlMany','MngmFinancialBack','MngmOverseaBack',\n",
    "# 'IsCocurP','ConcurrentPosition','ISHoldOtherFinaShares','ISHoldOtherFinaShares','ISHoldBankShares','ContrshrNature','PropertyRightsNature']\n",
    "# category_triples=[]\n",
    "# for i in tqdm(rpt_financial_varibles.index):\n",
    "#     year=rpt_financial_varibles.loc[i,'year']\n",
    "#     code=rpt_financial_varibles.loc[i,'Stkcd']\n",
    "#     for c in categories:\n",
    "#         c_v=rpt_financial_varibles.loc[i,c]\n",
    "#         category_triples.append([str(year)+'.comp.'+str(code),'cat.'+c,c+'.'+str(c_v)])\n",
    "# X+=category_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X).to_csv('KG0.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start KGE\n",
      "finished KGE\n",
      "finish get embedding\n"
     ]
    }
   ],
   "source": [
    "from ampligraph.latent_features import ComplEx\n",
    "rpt_financial_varibles.drop(['IndustryCode','EquityNatureID'],axis=1,inplace=True)\n",
    "for column in list(rpt_financial_varibles.columns[rpt_financial_varibles.isna().sum() > 0]):\n",
    "    mean_val = rpt_financial_varibles[column].mean()\n",
    "    rpt_financial_varibles[column].fillna(mean_val, inplace=True)\n",
    "print('start KGE')\n",
    "model =ComplEx(seed=555, epochs=1000, k=15, optimizer_params={'lr':0.01},batches_count=5)\n",
    "model.fit(np.array(X))\n",
    "print('finished KGE')\n",
    "def get_embedding(model,cwwb,with_row_feature=True):\n",
    "    if with_row_feature:\n",
    "        newCWWB=cwwb.copy()\n",
    "    else:\n",
    "        newCWWB=pd.DataFrame()\n",
    "    for i in cwwb.index:\n",
    "        try:\n",
    "            embedding=model.get_embeddings(str(cwwb.loc[i,'year'])+'company'+str(cwwb.loc[i,'Stkcd']))\n",
    "            j=0\n",
    "            for e in embedding:\n",
    "                newCWWB.loc[i,j]=e\n",
    "                j+=1\n",
    "        except:\n",
    "            print('no embedding for:',cwwb.loc[i,'Stkcd'])\n",
    "    \n",
    "    for j in range(0,len(embedding)):\n",
    "        newCWWB[j]=newCWWB[j].fillna(np.mean(newCWWB[j]))\n",
    "    newCWWB['label']=cwwb['label']\n",
    "    if with_row_feature:\n",
    "        FraudData=newCWWB.drop(['label','year','Stkcd'],axis=1).values\n",
    "    else:\n",
    "        FraudData=newCWWB.drop(['label'],axis=1).values\n",
    "    FraudLabl=newCWWB.loc[:,'label'].values\n",
    "    return FraudData,FraudLabl\n",
    "FraudData,FraudLabel=get_embedding(model,rpt_financial_varibles,with_row_feature=True)\n",
    "print('finish get embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total len of params comb:66\n",
      "train test split 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [22:02<00:00, 20.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:{'n_estimators': 2500, 'max_depth': None, 'min_sample_leaf': 1},bets auc on val set:0.7705323708352608\n",
      "test auc:0.7607116430620643\n",
      "train test split 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [21:37<00:00, 19.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:{'n_estimators': 3750, 'max_depth': None, 'min_sample_leaf': 5},bets auc on val set:0.765989758500598\n",
      "test auc:0.7398635590599876\n",
      "train test split 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [22:02<00:00, 20.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:{'n_estimators': 3000, 'max_depth': None, 'min_sample_leaf': 5},bets auc on val set:0.7716563997262149\n",
      "test auc:0.7705160916732264\n",
      "train test split 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [21:07<00:00, 19.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:{'n_estimators': 2500, 'max_depth': 20, 'min_sample_leaf': 1},bets auc on val set:0.7652856416957028\n",
      "test auc:0.7664211882787473\n",
      "train test split 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [21:46<00:00, 19.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:{'n_estimators': 4500, 'max_depth': None, 'min_sample_leaf': 5},bets auc on val set:0.7789678135405105\n",
      "test auc:0.7407893809940727\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "params_dict=[]\n",
    "ne=list(range(2500,5010,250))\n",
    "max_depth=[20,None]\n",
    "min_leaf=[1,5,10]\n",
    "iters=itertools.product(ne,max_depth,min_leaf)\n",
    "for comb in iters:\n",
    "    params_dict.append({'n_estimators':comb[0],'max_depth':comb[1],'min_sample_leaf':comb[2]})\n",
    "print('total len of params comb:{}'.format(len(params_dict)))\n",
    "exp=experiment_protocal(params_dict=params_dict,model='RF',exp_name='RF_simpleKGE',comment='RF with simple KGE, KGEepoch=1000,KDdim=15')\n",
    "re2=exp.run(FraudData,FraudLabel,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.7607116430620643,\n",
       "  0.7398635590599876,\n",
       "  0.7705160916732264,\n",
       "  0.7664211882787473,\n",
       "  0.7407893809940727],\n",
       " [0.7705323708352608,\n",
       "  0.765989758500598,\n",
       "  0.7716563997262149,\n",
       "  0.7652856416957028,\n",
       "  0.7789678135405105])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7556603726136196"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(re2[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RPT sub dataset\n",
    "\n",
    "### baseline\n",
    "\n",
    "([0.7598548673944933,\n",
    "  0.7363293328695115,\n",
    "  0.7613958180650181,\n",
    "  0.7656157832167196,\n",
    "  0.736743853716954],\n",
    "mean: 0.752\n",
    "\n",
    " [0.7616242874728514,\n",
    "  0.7732647814910025,\n",
    "  0.7595528825709252,\n",
    "  0.7660234672023498,\n",
    "  0.7666020922123209])\n",
    "\n",
    "### KGE\n",
    "\n",
    "simple KGE concatenated with row feature\n",
    "\n",
    "([0.7607116430620643,\n",
    "  0.7398635590599876,\n",
    "  0.7705160916732264,\n",
    "  0.7664211882787473,\n",
    "  0.7407893809940727],\n",
    "mean:0.75566\n",
    "  \n",
    " [0.7705323708352608,\n",
    "  0.765989758500598,\n",
    "  0.7716563997262149,\n",
    "  0.7652856416957028,\n",
    "  0.7789678135405105])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7519879310525394"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(re2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov=[]\n",
    "for i in range(FraudData.shape[1]):\n",
    "    cov.append(np.corrcoef(FraudData[:,i],FraudLabel)[0,1])\n",
    "print(np.sort(cov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a=np.corrcoef(rpt_financial_varibles.drop(['year','Stkcd'],axis=1),rowvar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total len of params comb:66\n",
      "train test split 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [20:38<00:00, 18.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:{'n_estimators': 4500, 'max_depth': None, 'min_sample_leaf': 1},bets auc on val set:0.7616242874728514\n",
      "test auc:0.7598548673944933\n",
      "train test split 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [20:19<00:00, 18.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:{'n_estimators': 3250, 'max_depth': None, 'min_sample_leaf': 5},bets auc on val set:0.7732647814910025\n",
      "test auc:0.7363293328695115\n",
      "train test split 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [20:19<00:00, 18.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:{'n_estimators': 4750, 'max_depth': 20, 'min_sample_leaf': 10},bets auc on val set:0.7595528825709252\n",
      "test auc:0.7613958180650181\n",
      "train test split 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [20:16<00:00, 18.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:{'n_estimators': 3500, 'max_depth': 20, 'min_sample_leaf': 1},bets auc on val set:0.7660234672023498\n",
      "test auc:0.7656157832167196\n",
      "train test split 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [20:27<00:00, 18.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:{'n_estimators': 5000, 'max_depth': 20, 'min_sample_leaf': 5},bets auc on val set:0.7666020922123209\n",
      "test auc:0.736743853716954\n"
     ]
    }
   ],
   "source": [
    "financial_featrues=rpt_financial_varibles\n",
    "X=financial_featrues.drop(['year','Stkcd','label'],axis=1)\n",
    "for column in list(X.columns[X.isna().sum() > 0]):\n",
    "    mean_val = X[column].mean()\n",
    "    X[column].fillna(mean_val, inplace=True)\n",
    "\n",
    "X=X.values\n",
    "y=financial_featrues['label'].values\n",
    "import itertools\n",
    "params_dict=[]\n",
    "ne=list(range(2500,5010,250))\n",
    "max_depth=[20,None]\n",
    "min_leaf=[1,5,10]\n",
    "iters=itertools.product(ne,max_depth,min_leaf)\n",
    "for comb in iters:\n",
    "    params_dict.append({'n_estimators':comb[0],'max_depth':comb[1],'min_sample_leaf':comb[2]})\n",
    "print('total len of params comb:{}'.format(len(params_dict)))\n",
    "exp=experiment_protocal(params_dict=params_dict,model='RF',exp_name='rpt_baseline',comment='RF baseline')\n",
    "re2=exp.run(X,y,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_featrues=rpt_financial_varibles\n",
    "X=financial_featrues.drop(['year','Stkcd','IndustryCode','label','EquityNatureID'],axis=1)\n",
    "for column in list(X.columns[X.isna().sum() > 0]):\n",
    "    mean_val = X[column].mean()\n",
    "    X[column].fillna(mean_val, inplace=True)\n",
    "\n",
    "X=X.values\n",
    "y=financial_featrues['label'].values\n",
    "import itertools\n",
    "params_dict=[]\n",
    "ne=list(range(2500,5010,250))\n",
    "max_depth=[20,None]\n",
    "min_leaf=[1,5,10]\n",
    "iters=itertools.product(ne,max_depth,min_leaf)\n",
    "for comb in iters:\n",
    "    params_dict.append({'n_estimators':comb[0],'max_depth':comb[1],'min_sample_leaf':comb[2]})\n",
    "print('total len of params comb:{}'.format(len(params_dict)))\n",
    "exp=experiment_protocal(params_dict=params_dict,model='RF',exp_name='tmp',comment='RF baseline')\n",
    "re2=exp.run(X,y,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "graph=pd.read_csv('./KG0.csv').values\n",
    "edges=[[x[0],x[2]]for x in graph]\n",
    "G=nx.Graph()\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "adj=nx.adjacency_matrix(G)\n",
    "adj_2=adj.dot(adj)\n",
    "adj_1_2=adj_2.toarray()+adj.toarray()\n",
    "nodes=list(G.nodes)\n",
    "comp_adj=adj_1_2[0:12186,0:12186]\n",
    "comp_nodes=nodes[0:12186]\n",
    "np.place(comp_adj,comp_adj>0,1)\n",
    "for i in range(len(comp_adj)):\n",
    "    comp_adj[i,i]=0\n",
    "\n",
    "\n",
    "select_index=[]\n",
    "drop_index=[]\n",
    "k=0\n",
    "for i in tqdm(comp_nodes):\n",
    "    year=int(i[0:4])\n",
    "    cp=int(i[11:])\n",
    "    ind=rpt_financial_varibles.query('Stkcd == @cp & year == @year')\n",
    "    if len(ind)==0:\n",
    "        drop_index.append(k)\n",
    "        k+=1\n",
    "        continue\n",
    "    k+=1\n",
    "    select_index.append(ind.index.values[0])\n",
    "tmp=np.delete(comp_adj,drop_index,axis=0)\n",
    "tmp=np.delete(tmp,drop_index,axis=1)\n",
    "comp_features=rpt_financial_varibles.loc[select_index]\n",
    "comp_features.to_csv('comp_Graph_features.csv',index=False)\n",
    "pd.DataFrame(tmp).to_csv('comp_Graph_adj',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "adj=pd.read_csv('comp_Graph_adj').values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "adj=csr_matrix(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del adj_1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_adj=adj.toarray()[0:12186,0:12186]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_adj=csr_matrix(comp_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del adj,adj_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=nx.from_scipy_sparse_matrix(comp_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "graph=pd.read_csv('./KG1.csv')\n",
    "graph=graph.loc[[graph.iloc[i,1]=='same.Company' or graph.iloc[i,1]=='relatedTransaction' for i in range(len(graph))]]\n",
    "graph=graph.values\n",
    "edges=[[x[0],x[2]]for x in graph]\n",
    "G=nx.Graph()\n",
    "G.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_node=rpt_financial_varibles.apply(lambda x:str(x['year'])+'.comp.'+str(x['Stkcd'] ),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "borad=pd.read_csv('./borad.csv')[['Stkcd','year','PersonID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "borad['comp']=borad.apply(lambda x: str(x['year'])+'.comp.'+str(x['Stkcd']),axis=1)\n",
    "borad['person']=borad.apply(lambda x: 'null'+'.person.'+str(x['PersonID']),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "borad_edges=borad[['comp','person']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges=borad_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9366/9366 [00:01<00:00, 5865.62it/s]\n"
     ]
    }
   ],
   "source": [
    "select_index=[]\n",
    "k=0\n",
    "for i in tqdm(industry_triples):\n",
    "    if i[0] in comp_node.values :\n",
    "        select_index.append(k)\n",
    "    k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges=np.array(industry_triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2003.comp.600225', 'industry', '2003ind.A01'], dtype='<U16')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G=nx.Graph()\n",
    "G.add_edges_from(edges[:,[0,2]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj=nx.adjacency_matrix(G)\n",
    "adj_2=adj.dot(adj)\n",
    "nodes=list(G.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "mE=[]\n",
    "for i in nx.from_scipy_sparse_matrix(adj_2).edges():\n",
    "    if nodes[i[0]].split('.')[1]=='comp' and nodes[i[1]].split('.')[1]=='comp':\n",
    "        mE.append([nodes[i[0]],'same.industry',nodes[i[1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(mE).to_csv('sameIndustry.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X+=mE\n",
    "pd.DataFrame(X).to_csv('KG2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_adj=adj_1_2[0:9366,0:9366]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "sparse.save_npz('RT_SC_B_v2.npz',comp_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpt_financial_varibles.index=comp_node\n",
    "rpt_financial_varibles=rpt_financial_varibles.loc[nodes[0:9366],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpt_financial_varibles.to_csv('RT_SC_B_features_v2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc=[]\n",
    "for i in nx.connected_components(G):\n",
    "    cc.append(i)\n",
    "len_cc=[len(i) for i in cc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "G=nx.from_scipy_sparse_matrix(comp_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc=[]\n",
    "for i in nx.connected_components(G):\n",
    "    cc.append(i)\n",
    "cc_len=[len(i) for i in cc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ce0e62306dd6a5716965d4519ada776f947e6dfc145b604b11307c10277ef29"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
